{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача\n",
    "Загрузите данные train.csv, оставьте в данных только признаки 'fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due', 'compliance', затем избавьтесь от пропусков.\n",
    "\n",
    "Обучим модель на несбалансированных данных. Целевой переменной будет 'compliance', разделите данные на обучающую и тестовую выборки в соотношении 70%/30% без перемешивания.\n",
    "\n",
    "Обучите DecisionTreeClassifier из scikit-learn с параметром random_state=23. Посчитайте значения метрики F1 на тренировочной выборке и на тестовой выборке.\n",
    "\n",
    "Затем сделайте эту же выборку сбалансированной с помощью undersampling.\n",
    "\n",
    "Для этого посчитайте количество примеров (n) класса-меньшинства, затем из класса-большинства возьмите n первых примеров.\n",
    "\n",
    "То есть, в терминологии Python, возьмите срез (slice) от начала и до n, где n — количество примеров класса, которого в выборке представлено меньше.\n",
    "\n",
    "Соедините две части выборки (с уменьшенным классом-большинством и с изначальным классом-меньшинством), сделайте точно такое же разбиение, как в задаче выше, и обучите такую же модель.\n",
    "\n",
    "Посчитайте значение метрики F1 на новой тестовой выборке с помощью новой модели. Вычтите из значения метрики на тестовой части сбалансированной выборки значение метрики на тестовой части несбалансированной выборки и запишите результат в переменную result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = pd.read_csv(\"train11.csv\", encoding = 'ISO-8859-1', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Напишите ваш код ниже\n",
    "# оставьте в данных только признаки 'fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due', 'compliance',\n",
    "# затем избавьтесь от пропусков.\n",
    "data = vis_data[['fine_amount', 'state_fee', 'late_fee', 'discount_amount', 'balance_due', 'compliance']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучим модель на несбалансированных данных. Целевой переменной будет 'compliance', \n",
    "# разделите данные на обучающую и тестовую выборки в соотношении 70%/30% без перемешивания.\n",
    "# Обучите DecisionTreeClassifier из scikit-learn с параметром random_state=23. Посчитайте значения метрики f1 \n",
    "# на тренировочной выборке и на тестовой выборке.\n",
    "X1 = data.drop('compliance', axis=1)\n",
    "y1 = data['compliance']\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, shuffle=False, random_state=23)\n",
    "\n",
    "clf1 = DecisionTreeClassifier(random_state=23)\n",
    "clf1.fit(X1_train, y1_train)\n",
    "\n",
    "y1_pred_train = clf1.predict(X1_train)\n",
    "f1_1_train = f1_score(y1_train,y1_pred_train)\n",
    "\n",
    "y1_pred_test = clf1.predict(X1_test)\n",
    "f1_1_test = f1_score(y1_test,y1_pred_test)\n",
    "#print('f1_1_train', f1_1_train, 'f1_1_test', f1_1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Затем сделайте эту же выборку сбалансированной с помощью undersampling.\n",
    "# Для этого посчитайте количество примеров (n) класса-меньшинства, затем из класса-большинства возьмите n первых примеров.\n",
    "# То есть, в терминологии Python, возьмите срез (slice) от начала и до n, где n — количество примеров класса, \n",
    "# которого в выборке представлено меньше.\n",
    "X = data.drop('compliance', axis=1)\n",
    "y = data['compliance']\n",
    "\n",
    "zeros = y[y == 0.0]\n",
    "ones = y[y == 1.0]\n",
    "down_index = list(zeros.index[:len(ones)]) + list(ones.index)\n",
    "X_down = X.loc[down_index, :]\n",
    "y_down = y[down_index]\n",
    "\n",
    "X_down_train, X_down_test, y_down_train, y_down_test = train_test_split(X_down, y_down,\n",
    "                                                                        test_size=0.3, shuffle=False, random_state=23)\n",
    "clf2 = DecisionTreeClassifier(random_state=23)\n",
    "clf2.fit(X_down_train, y_down_train)\n",
    "\n",
    "# Посчитайте значение метрики f1 на новой тестовой выборке с помощью новой модели.\n",
    "y_down_pred_train = clf2.predict(X_down_train)\n",
    "f1_2_train = f1_score(y_down_train,y_down_pred_train)\n",
    "\n",
    "y_down_pred_test = clf2.predict(X_down_test)\n",
    "f1_2_test = f1_score(y_down_test,y_down_pred_test)\n",
    "#print('f1_2_train', f1_2_train, 'f1_2_test', f1_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычтите из значения метрики на тестовой части сбалансированной выборки значение метрики на тестовой\n",
    "# части несбалансированной выборки и запишите результат в переменную result.\n",
    "result = f1_2_test - f1_1_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
